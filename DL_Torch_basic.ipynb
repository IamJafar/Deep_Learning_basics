{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62dda6c3-23bc-4e83-ad43-a47f8b8babe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf7410-b0cb-4d0a-8c65-f69edf3dcd88",
   "metadata": {},
   "source": [
    "## Array using Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53fe555-c935-4b5e-9c50-ddee2e557346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b8b279-c600-4ec5-8fa6-ac9d5f64a9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4393, 0.8118],\n",
       "        [0.1083, 0.5204]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf27182-1c6b-4441-a73e-7360452e072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6451, 0.5495, 0.8725, 0.0698, 0.4518],\n",
      "        [0.4758, 0.4186, 0.8639, 0.2717, 0.1211],\n",
      "        [0.9148, 0.1816, 0.4429, 0.4627, 0.4286]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,5)\n",
    "print(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7638b3f-4939-4c05-8253-7515f33ed234",
   "metadata": {},
   "source": [
    "## Array using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c51f73e-ce47-444a-b491-9aa1751891f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 8, 9],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[7,8,9],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98f52441-7bd3-4043-8851-d1931ce31541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92512687, 0.46447765, 0.22715422, 0.74111427, 0.53988287],\n",
       "       [0.70356362, 0.65977961, 0.79985837, 0.941016  , 0.66739363],\n",
       "       [0.65174978, 0.22927659, 0.03476242, 0.12687789, 0.17947045]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ca748a-9bcc-43ea-bc11-4dcf3754adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2,2)\n",
    "b = torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c37bfb-badd-416e-83da-3e09ca8b2dd3",
   "metadata": {},
   "source": [
    "## Multiplication and Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0d1c4c4-c3ed-46f2-a810-08cc4a969365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7064, 0.6461],\n",
       "        [0.2315, 0.2626]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fcbe079-73cb-4341-a243-8c7528ba986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7063823 , 0.6460733 ],\n",
       "       [0.23150918, 0.26263553]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d59a8f-a829-4ea1-a844-c89829d6f597",
   "metadata": {},
   "source": [
    "a* b and np.multiply are same 1st*1st 2nd*2nd\n",
    "\n",
    "torch.matmul and np.dot are same which uses matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d08e808-aea6-4b3e-8cc9-3e6a635ae2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6960, 0.0187],\n",
       "        [0.0048, 0.2540]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3062c6a-6f66-44e4-a053-fdaad49f3006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6960, 0.0187],\n",
       "        [0.0048, 0.2540]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59b808ca-641b-4e7b-a0ac-9d0dcfe3e24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6752, 0.8426],\n",
      "        [0.6329, 0.8533]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6752, 0.8426],\n",
       "        [0.6329, 0.8533]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a+b)\n",
    "torch.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa4f246-4fde-494a-a349-81594afeef75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6752, 0.8426],\n",
       "        [0.6329, 0.8533]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138c489-80ea-475f-aad6-c4678149494e",
   "metadata": {},
   "source": [
    "### Uninitialized or Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3a86078-22c1-4e0d-bb59-4b8b5f170002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.6123e-39, 7.6225e-39, 8.4490e-39, 1.0102e-38],\n",
      "        [9.0919e-39, 1.0102e-38, 8.9082e-39, 8.4489e-39],\n",
      "        [9.6429e-39, 8.4490e-39, 9.6429e-39, 9.2755e-39],\n",
      "        [1.0286e-38, 9.0919e-39, 8.9082e-39, 9.2755e-39]])\n"
     ]
    }
   ],
   "source": [
    "e = torch.empty(4,4)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726036c5-6113-4dfc-8aa9-7ba16b83da17",
   "metadata": {},
   "source": [
    "### Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36c526ca-86d6-4633-83b4-f212740b7a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.zeros(4,3)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d0efde4-b8be-4ed4-82db-2c7878b9456b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d030441c-6fa5-49de-b356-a6b8db24d75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,3,dtype= torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52c36276-794c-4047-b7a2-95924ef0a37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8cdd0df6-f937-418d-9aae-66c59be73416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((5,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b156e-ba33-4f50-99e7-6f899d4d6dac",
   "metadata": {},
   "source": [
    "### Identity and Eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61e10983-4cd1-4a2b-8554-a0041e1bc494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.identity(3)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f695a00-a758-4c6d-bb78-88bd384e9a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.eye(3)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb1058-0d44-4ff7-89d4-7c4282277faf",
   "metadata": {},
   "source": [
    "### Numpy array to torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df4366bc-ee98-47c8-9c57-88b6e0d9bc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.from_numpy(i)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a54f1248-1b4c-4f6a-9892-11d3a6acbf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor to numpy array\n",
    "e.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2b220-ca19-4930-b680-5c00e13a37be",
   "metadata": {},
   "source": [
    "## Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e89dad5-8e72-4cc6-9807-6da3bcaedeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.rand(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47092a23-0bcc-4563-ac8d-e50aaa86c74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2041, 0.8621, 0.9627, 0.1136],\n",
       "        [0.3600, 0.0345, 0.0108, 0.5727],\n",
       "        [0.0583, 0.4909, 0.0277, 0.8990],\n",
       "        [0.4388, 0.5824, 0.9688, 0.4591]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1fb04d-c51c-494b-9304-e0b72ed3bf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8621, 0.0345, 0.4909, 0.5824])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85668497-6c6f-470b-8ff0-22e5e01eb1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3892,  1.1748, -1.1716, -1.5329],\n",
       "        [-0.4552, -0.0256, -0.0788,  0.0546],\n",
       "        [-1.0449, -1.5923,  1.0532, -0.8044],\n",
       "        [ 0.4828, -0.1064,  0.6598,  1.2202]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will give valuse from standard normal distribution(- to +)\n",
    "torch.randn(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a1e8bf2-d7e3-4065-8151-16e1d530d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2041, 0.8621, 0.9627, 0.1136, 0.3600, 0.0345, 0.0108, 0.5727, 0.0583,\n",
      "        0.4909, 0.0277, 0.8990, 0.4388, 0.5824, 0.9688, 0.4591])\n",
      "tensor([[0.2041, 0.8621],\n",
      "        [0.9627, 0.1136],\n",
      "        [0.3600, 0.0345],\n",
      "        [0.0108, 0.5727],\n",
      "        [0.0583, 0.4909],\n",
      "        [0.0277, 0.8990],\n",
      "        [0.4388, 0.5824],\n",
      "        [0.9688, 0.4591]])\n",
      "tensor([[0.2041, 0.8621, 0.9627, 0.1136, 0.3600, 0.0345, 0.0108, 0.5727],\n",
      "        [0.0583, 0.4909, 0.0277, 0.8990, 0.4388, 0.5824, 0.9688, 0.4591]])\n"
     ]
    }
   ],
   "source": [
    "y1 = mat.view(16)\n",
    "print(y1)\n",
    "y2 = mat.view(-1,2)\n",
    "print(y2)\n",
    "y3 = mat.view(2,-1)\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3f687-a005-423e-b4d7-620fa1e8fb05",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2803c26b-77ac-4117-b221-e803fb9d97c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([2])\n",
    "b = torch.tensor([-4])\n",
    "c = torch.tensor([-2])\n",
    "d = torch.tensor([2])\n",
    "\n",
    "e = a+b\n",
    "f = c*d\n",
    "\n",
    "g = e*f\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e3895-48c8-4938-92a7-8b1b83a0f6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0e38227-e234-4820-9e64-e834d03e32b4",
   "metadata": {},
   "source": [
    "## Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbefb58c-50d2-4b74-9447-1d8a75204af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.]) tensor([8.]) tensor([32.]) tensor([16.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3.],requires_grad=True)\n",
    "b = torch.tensor([5.],requires_grad=True)\n",
    "c = torch.tensor([2.],requires_grad=True)\n",
    "d = torch.tensor([4.],requires_grad=True)\n",
    "\n",
    "e = a+b\n",
    "f = c*d\n",
    "\n",
    "r = e *f\n",
    "\n",
    "r.backward()\n",
    "print(a.grad,b.grad,c.grad,d.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce204345-4369-4f75-9e71-8aaccd82efc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5323ff6-6ab3-4120-84e5-58184e369edc",
   "metadata": {},
   "source": [
    "## Fully connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e3d8281-b212-435c-a750-9cbe2d436eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0283, 1.7952, 2.2020, 1.9236, 2.5687, 2.7295, 1.8487, 2.2590, 3.3236,\n",
      "        2.0414, 2.2264, 2.7946, 2.1390, 2.9071, 3.2669, 2.6007, 1.8940, 3.1074,\n",
      "        2.9057, 3.1515])\n",
      "tensor([27.1523, 24.7745, 18.7990, 25.4979, 22.4448, 23.3391, 18.8543, 17.9284,\n",
      "        29.9506, 20.4610, 24.6769, 29.6728, 34.9653, 20.9734, 22.3888, 29.5052,\n",
      "        28.8368, 28.6883, 28.4571, 27.1506])\n",
      "tensor([254.0937, 284.9214, 241.5870, 264.5339])\n"
     ]
    }
   ],
   "source": [
    "inp_layer = torch.rand(10)\n",
    "\n",
    "w1 = torch.rand(10,20)\n",
    "w2 = torch.rand(20,20)\n",
    "w3 = torch.rand(20,4)\n",
    "\n",
    "h1 = torch.matmul(inp_layer,w1)\n",
    "h2 = torch.matmul(h1,w2)\n",
    "\n",
    "out_layer = torch.matmul(h2,w3)\n",
    "\n",
    "print(h1)\n",
    "print(h2)\n",
    "\n",
    "print(out_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408de4a1-4ef4-4fa0-bc3a-a43e6d0adba5",
   "metadata": {},
   "source": [
    "## Building a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07639aa-efd0-460b-b4ee-6dfc62c1a246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0822, -0.0992, -0.1183,  0.2308], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,20)\n",
    "        self.output = nn.Linear(20,4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "input_layer = torch.rand(10)\n",
    "net = Net()\n",
    "res = net(input_layer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3da82-ad23-4705-a685-cc9f7640fcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d77be7a0-301a-4edb-8477-ca4fa13839d1",
   "metadata": {},
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74956f3e-695b-46cb-ba99-df9b537d0688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6532, -0.2019])\n",
      "tensor([-0.6532, -0.2019])\n"
     ]
    }
   ],
   "source": [
    "il = torch.tensor([0.0401,-0.9005])\n",
    "\n",
    "w1 = torch.tensor([[-0.1094,-0.8285],[0.3327,-0.0461]])\n",
    "\n",
    "w2 = torch.tensor([[0.6856,-1.7650],[-0.1092,-0.1620]])\n",
    "\n",
    "w3 = torch.tensor([[0.8824,0.1268],[-0.8753,-0.3277]])\n",
    "\n",
    "h1 = torch.matmul(il,w1)\n",
    "h2 = torch.matmul(h1,w2)\n",
    "\n",
    "# using hidden layers\n",
    "o = torch.matmul(h2,w3)\n",
    "print(o)\n",
    "\n",
    "# using weight composed\n",
    "wc = torch.matmul(w1,w2)\n",
    "fw = torch.matmul(wc,w3)\n",
    "O = torch.matmul(il,fw)\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "659c1833-cd67-4c05-91a3-21358875f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0.])\n",
      "tensor([-0.1852, -0.0266])\n"
     ]
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "\n",
    "il = torch.tensor([0.0401,-0.9005])\n",
    "w1 = torch.tensor([[-0.1094,-0.8285],[0.3327,-0.0461]])\n",
    "w2 = torch.tensor([[0.6856,-1.7650],[-0.1092,-0.1620]])\n",
    "w3 = torch.tensor([[0.8824,0.1268],[-0.8753,-0.3277]])\n",
    "\n",
    "ah1 = relu(torch.matmul(il,w1))\n",
    "ah2 = relu(torch.matmul(ah1,w2))\n",
    "\n",
    "print(torch.matmul(ah2,w3))\n",
    "\n",
    "wc = relu(torch.matmul(w1,w2))\n",
    "fw = relu(torch.matmul(wc,w3))\n",
    "\n",
    "print(torch.matmul(il,fw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c422b06-c98f-4bc9-b4d6-2cae33d04874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 0.])\n",
      "tensor([[2.0000, 0.0000],\n",
      "        [1.2000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "\n",
    "t1 = torch.tensor([2.,-4.])\n",
    "\n",
    "print(relu(t1))\n",
    "\n",
    "t2 = torch.tensor([[2.,-4.],[1.2,0.]])\n",
    "\n",
    "print(relu(t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d28384-a743-4a37-8615-cdf466b8242a",
   "metadata": {},
   "source": [
    "## Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40ea6633-2a4c-4710-9e8f-721da5db848c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4271)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.rand([1,1000])\n",
    "ground_truth = torch.tensor([437])\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = cross_entropy(logits,ground_truth)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060d2ae-32fa-4e5c-8e0b-03d69f7ba9b8",
   "metadata": {},
   "source": [
    "# Preparing Dataset in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb3cae0-4701-4130-b278-26098ae5340b",
   "metadata": {},
   "source": [
    "### CIFAR10 Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5424e2dd-193b-4473-8e07-f57e413b7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4914,0.48216,0.44653),\n",
    "                                                     (0.24703,0.24349,0.26159))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a12d67-88b1-490d-b0ca-5bab3ca4e0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = torchvision.datasets.CIFAR10(root='./data', train=True,download=True,transform= transform,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011e1593-22a6-441f-9c83-1df0a49bbb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test = torchvision.datasets.CIFAR10(root='./data', train=False,download=True,transform= transform,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e3ff1f-d978-448e-ba62-d069d6bc1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f0e71e4-dc74-4b73-8395-538d1095afc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n",
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(trainloader.dataset.data.shape,testloader.dataset.data.shape)\n",
    "print(trainloader.batch_size)\n",
    "print(testloader.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916785a-3da7-4bbc-a6a7-e7ddc8d0d568",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b3e82b-b5db-488b-83c3-462d68168675",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307),(0.3081))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42532ac-d49d-4b17-be2a-4233635d5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.MNIST(root='./data', train=True,download=True,transform= transform)\n",
    "test = torchvision.datasets.MNIST(root='./data', train=False,download=True,transform= transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6547eebe-5fb5-4186-aa01-dcc6a2a53993",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainload = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True,num_workers=0)\n",
    "testload = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1f3cfe8-4339-48af-be82-bec4c4197c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(trainload.dataset.data.shape)\n",
    "print(testload.dataset.test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3d59e97-4a05-465f-8357-ca8ece21d17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(trainload.batch_size)\n",
    "print(testload.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e63cce-648a-40e5-be25-920de4174337",
   "metadata": {},
   "source": [
    "## Creating Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3a73e-3680-4d45-9d8b-f311770e25f7",
   "metadata": {},
   "source": [
    "#### CIFAR 10 consist of 10 classes with 32 *32 size and has 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aa85a98-f7cd-4f6b-b0f9-5a7eb90347b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3,500)\n",
    "        self.fc2 = nn.Linear(500,10)\n",
    "        # instantiate all 2 linear layers\n",
    "        \n",
    "        # use the instantiated layers and return x\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74df77b-ab1b-45cd-9f03-ba8890dea0bb",
   "metadata": {},
   "source": [
    "## Training the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a026ad6-778e-46b1-937b-0b02d0b3956c",
   "metadata": {},
   "source": [
    " First we instantiate the Net, the loss(cross-entropy), and the optimizer(adam)\n",
    " \n",
    " Adam optimizer works very well and is a version of gradient descent\n",
    " \n",
    " Then we loop 10 times over the entire dataset. We use zero_grad() function in order to not accumulate gradients from previous iterations\n",
    " \n",
    " when using iterators, we need to keep track of the number of items in the iterator. This is achieved by an inbuilt method called enumerate()\n",
    " \n",
    " The forward step is done using net(inputs), giving the result (output)\n",
    " \n",
    " we compute the loss function in the next line, and then we compute the gradients using loss.backward()\n",
    " \n",
    " Finally, we change the weights using optimizer with optimizer.step() command\n",
    " \n",
    " The line inputs = inputs.view(-1, 32*32*3) simply puts all entries o the images into vectors\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a49f126c-3d60-47a8-87b5-8fbb8fa39f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 3e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 32*32*3)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f828fd83-93a1-49ed-818c-d54c46be7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is : 52 %\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0,0\n",
    "predictions = []\n",
    "net.eval()\n",
    "\n",
    "for i, data in enumerate(testloader,0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 32*32*3)\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('The testing set accuracy of the network is : %d %%' % (100 * correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fe5d66-4a43-4c16-a569-7a293a16394e",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0ce0f-d86a-4ed5-8301-b7ddb7defbe2",
   "metadata": {},
   "source": [
    "### OOP way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf1afa32-2c2b-492a-8686-22cfb79269d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand(16,3,32,32)\n",
    "\n",
    "conv_filter = torch.nn.Conv2d(in_channels=3,\n",
    "                             out_channels=1,\n",
    "                             kernel_size=5,\n",
    "                             stride=1,\n",
    "                             padding=0)\n",
    "\n",
    "output_feature = conv_filter(image)\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555501f-56e8-4caa-8833-84b5ac6f2f0b",
   "metadata": {},
   "source": [
    "## Functional way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59992c42-6a31-44d2-9c81-9813a4644b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand(16,3,32,32)\n",
    "\n",
    "filt = torch.rand(1,3,5,5)\n",
    "\n",
    "out_feat_F = F.conv2d(image,filt,stride=1,padding=0)\n",
    "\n",
    "print(out_feat_F.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe50cb2-9074-4163-85cb-0cda3ed45d55",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c088e70-1739-4962-91d5-ac6d6dc18510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[6., 9.],\n",
      "          [3., 4.]]]])\n"
     ]
    }
   ],
   "source": [
    "im = torch.Tensor([[[[3,1,3,5],\n",
    "                     [6,0,7,9],\n",
    "                     [3,2,1,4],\n",
    "                     [0,2,4,3]]]])\n",
    "\n",
    "max_pool = torch.nn.MaxPool2d(2)\n",
    "\n",
    "out_feature = max_pool(im)\n",
    "print(out_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0314e068-9505-4a86-bced-af732311e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[6., 9.],\n",
      "          [3., 4.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Functional way\n",
    "im = torch.Tensor([[[[3,1,3,5],\n",
    "                     [6,0,7,9],\n",
    "                     [3,2,1,4],\n",
    "                     [0,2,4,3]]]])\n",
    "out_feature = F.max_pool2d(im,2)\n",
    "\n",
    "print(out_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c96f63-7ff9-4a44-91f3-cdff3366c28d",
   "metadata": {},
   "source": [
    "# Building a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83aa1a7b-9383-4a01-89c4-fa53a6c3d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc = nn.Linear(128 * 4 * 4,num_classes)\n",
    "        \n",
    "    def forwaeed(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        x = x.view(-1,128 * 4 * 4)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d401100-2e08-4aa9-8d90-87e8a4d43ded",
   "metadata": {},
   "source": [
    "### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b014803-2e74-4137-9173-cdd5cb102b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8068b94-efd0-4021-af6d-ea0330342a70",
   "metadata": {},
   "source": [
    "### Training a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b7a4c0-c656-405d-8390-087f7f513ff3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrainloader\u001b[49m,\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      3\u001b[0m         inputs,labels \u001b[38;5;241m=\u001b[39mdata\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a7116-9f15-4524-b476-7f757c7f9a6d",
   "metadata": {},
   "source": [
    "### Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c2914f-fddf-46fb-9a4d-1c5101f1ea4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtestloader\u001b[49m, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      5\u001b[0m     inputs,labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testloader' is not defined"
     ]
    }
   ],
   "source": [
    "correct, total = 0,0\n",
    "predictions = []\n",
    "net.eval()\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs,labels = data\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('The testing set accuracy of the network is : %d %%' % (100 * correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a98b9-42fe-48f5-95c4-f4066d72f0f3",
   "metadata": {},
   "source": [
    "## Sequential Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58c8ba86-d658-404f-93cd-3705ae6860bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        # Declare all the layers for feature extraction\n",
    "        self.features = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1),\n",
    "                                      nn.MaxPool2d(2,2), nn.ReLU(inplace=True),\n",
    "                                      nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1),\n",
    "                                      nn.MaxPool2d(2,2), nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(7*7*40,1024),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(1024,2048),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(2048,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34425e3-8aba-4b06-832c-bc5ecedefb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    \n",
    "    x = x.view(-1 , 7*7*40)\n",
    "    \n",
    "    x = self.classifier(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569ce6c3-5249-4616-910a-46486bd015ae",
   "metadata": {},
   "source": [
    "### Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "687f794e-dea3-44c5-9a68-39e7dd523bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(60000)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
    "                                                                     transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307),(0.3081))])),\n",
    "                                          batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:55000]))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
    "                                                                     transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307),(0.3081))])),\n",
    "                                          batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[55000:]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(root='./data', download=True, train=False,\n",
    "                                                                     transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307),(0.3081))])),\n",
    "                                          batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cae1b413-c587-4345-abcf-5b7a0e6dfc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.fc = nn.Linear(7*7*10,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 7*7*10)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5032d563-e91a-4712-8b2b-c59ea451c6e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training cnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrainloader\u001b[49m,\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      5\u001b[0m         inputs,labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "# Training cnn\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb021f1-468b-4dc9-b358-29b22d03f6d5",
   "metadata": {},
   "source": [
    "### Evaluating the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbb87ce9-13c6-41a4-891f-e1d5c8d58cb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [Net] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      5\u001b[0m     inputs,labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:363\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] is missing the required \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Module [Net] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "correct, total = 0,0\n",
    "predictions = []\n",
    "net.eval()\n",
    "for i, data in enumerate(val_loader, 0):\n",
    "    inputs,labels = data\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('The testing set accuracy of the network is : %d %%' % (100 * correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2eb3473-6cc2-46c8-b970-96ccd06e546e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtestloader\u001b[49m, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      5\u001b[0m     inputs,labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testloader' is not defined"
     ]
    }
   ],
   "source": [
    "correct, total = 0,0\n",
    "predictions = []\n",
    "net.eval()\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs,labels = data\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('The testing set accuracy of the network is : %d %%' % (100 * correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9f92f-04e5-4232-b2d3-39b74a4153cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e03f5b-23d7-46c4-9019-6ca4df4f4865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
